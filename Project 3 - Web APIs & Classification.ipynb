{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8Z1G_WG1ckt"
   },
   "source": [
    "<div class=\"alert\" style=\"background-color:#fff; color:white; padding:0px 10px; border-radius:5px;\"><h1 style='margin:15px 15px; color:#006a79; font-size:40px'>Subreddit classification - r/wallstreetbets & r/valueinvesting</h1>\n",
    "</div>\n",
    "\n",
    "Reddit is an online forum where users can post ideas/ contents in groups called subreddits. It is widely popular and naturally this provides us with a huge database of text data regarding a certain topic. In this notebook, we seek to explore the use of natural language processing in classifying which subreddit does a post belong to.\n",
    "\n",
    "We have selected r/wallstreetbets and r/valueinvesting as the subreddits in this study. These are 2 subreddits that discuss about investments in the financial markets, most of the posts are either questions regarding investing or investment pitches. Where the 2 subreddits defer is on the style of investing as well as the tone of discussion. r/wallstreetbets is more casual and filled with memes, their general investment methodology includes going all in (or YOLO) into high risk growth stocks hoping for it to go to the moon. r/valueinvesting is more serious in its discussion, their investment methodology is (as the title says) value investing where they place emphasis on the companyâ€™s fundamentals.\n",
    "\n",
    "Classifying between the 2 subreddits is particularly interesting. A well-developed model that can distinguish between the 2 subreddits can be extended to a model that can interpret a given text related to investment (e.g. investment advise) is classified as value investing, growth investing or just meme investing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "To what extent can a classification model distinguish between posts from r/wallstreetbets and r/valueinvesting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "In this project file, we used Reddit's API to extract posts from the subreddits r/wallstreetbets and r/valueinvesting. After cleaning the data we are left with 825 post from r/wallstreetbets and 705 from r/valueinvesting. The models used in this study are Logistic Regression, Support Vector Machine (SVM), Naive Bayes Classification. To select the optimal classification model, we will be using GridSearchCV to compare the scores of models. Each model will be run twice, once with a CountVectorizer and the second time with a TfidfVectorizer; this leaves us with 6 models to compare.\n",
    "\n",
    "After comparing models evaluation metrics, the model with SVM and TfidfVectorizer was the best with an accuracy score of 90.9% (baseline 54%). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGFNuG-w1cku"
   },
   "source": [
    "### Content:\n",
    "1. [Load the Data](#1)\n",
    "  \n",
    "2. [Pre-processing Data](#2)\n",
    "  \n",
    "3. [Exploratory Data Analysis](#3)\n",
    "\n",
    "4. [Modeling](#4)\n",
    "\n",
    "5. [Hyperparameter Tuning](#5)\n",
    "\n",
    "6. [Conclusion and Evaluation](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3CAWyIl1cky"
   },
   "source": [
    "<a id='1'></a>\n",
    "# 1. Load the Data\n",
    "\n",
    "In this section we will:\n",
    "\n",
    "- Import the libraries\n",
    "- Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJ87ElRJ1ckz"
   },
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "id": "PD4FhFf-1ck1"
   },
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "\n",
    "# Data Manipulation\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score, roc_auc_score, plot_roc_curve, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#NLP libraries\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import regex as re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCmOHLQ71ck2"
   },
   "source": [
    "### Load the datasets\n",
    "\n",
    "The 2 dataset used in this study was extracted via Reddit's API. A seperate notebook was used to extract the data. As we were unable to a large enough data set from 1 API pull (reddit API could not get more than 250 post), several pull attempts were taken and combined to form the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "id": "lumwjIQr1ck2",
    "outputId": "1a064bc8-67ec-4028-ad88-a9fa0c9d991f"
   },
   "outputs": [],
   "source": [
    "# Read csvs\n",
    "wsb = pd.read_csv('wsb.csv')\n",
    "value = pd.read_csv('valueinvesting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>hidden</th>\n",
       "      <th>pwls</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th>downs</th>\n",
       "      <th>top_awarded_type</th>\n",
       "      <th>hide_score</th>\n",
       "      <th>name</th>\n",
       "      <th>quarantine</th>\n",
       "      <th>link_flair_text_color</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>subreddit_type</th>\n",
       "      <th>ups</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>media_embed</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>secure_media</th>\n",
       "      <th>is_reddit_media_domain</th>\n",
       "      <th>is_meta</th>\n",
       "      <th>category</th>\n",
       "      <th>secure_media_embed</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>can_mod_post</th>\n",
       "      <th>score</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>is_created_from_ads_ui</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>edited</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>gildings</th>\n",
       "      <th>content_categories</th>\n",
       "      <th>is_self</th>\n",
       "      <th>mod_note</th>\n",
       "      <th>created</th>\n",
       "      <th>link_flair_type</th>\n",
       "      <th>wls</th>\n",
       "      <th>removed_by_category</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>domain</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>selftext_html</th>\n",
       "      <th>likes</th>\n",
       "      <th>suggested_sort</th>\n",
       "      <th>banned_at_utc</th>\n",
       "      <th>url_overridden_by_dest</th>\n",
       "      <th>view_count</th>\n",
       "      <th>archived</th>\n",
       "      <th>no_follow</th>\n",
       "      <th>is_crosspostable</th>\n",
       "      <th>pinned</th>\n",
       "      <th>over_18</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>awarders</th>\n",
       "      <th>media_only</th>\n",
       "      <th>link_flair_template_id</th>\n",
       "      <th>can_gild</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>locked</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>treatment_tags</th>\n",
       "      <th>visited</th>\n",
       "      <th>removed_by</th>\n",
       "      <th>num_reports</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>mod_reason_by</th>\n",
       "      <th>removal_reason</th>\n",
       "      <th>link_flair_background_color</th>\n",
       "      <th>id</th>\n",
       "      <th>is_robot_indexable</th>\n",
       "      <th>report_reasons</th>\n",
       "      <th>author</th>\n",
       "      <th>discussion_type</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>contest_mode</th>\n",
       "      <th>mod_reports</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>permalink</th>\n",
       "      <th>parent_whitelist_status</th>\n",
       "      <th>stickied</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>media_metadata</th>\n",
       "      <th>is_gallery</th>\n",
       "      <th>gallery_data</th>\n",
       "      <th>author_cakeday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_5cnwr7fm</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Pentagon UAP report supposed to be released by...</td>\n",
       "      <td>[{'e': 'text', 't': 'News'}]</td>\n",
       "      <td>r/wallstreetbets</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_o6ugzt</td>\n",
       "      <td>False</td>\n",
       "      <td>light</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>News</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624542e+09</td>\n",
       "      <td>richtext</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>dailywire.com</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confidence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.dailywire.com/news/pentagon-ufo-re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>519c3d26-4acc-11eb-8ce2-0ec530aa616d</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#ffb000</td>\n",
       "      <td>o6ugzt</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alexbinfordwalsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>some_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/wallstreetbets/comments/o6ugzt/pentagon_uap...</td>\n",
       "      <td>some_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.dailywire.com/news/pentagon-ufo-re...</td>\n",
       "      <td>10582267</td>\n",
       "      <td>1.624513e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_458fq</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Retard gets a margin call</td>\n",
       "      <td>[{'e': 'text', 't': 'Meme'}]</td>\n",
       "      <td>r/wallstreetbets</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>meme</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_o6udmp</td>\n",
       "      <td>False</td>\n",
       "      <td>light</td>\n",
       "      <td>0.84</td>\n",
       "      <td>#dadada</td>\n",
       "      <td>public</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>78806c26-46a2-11e9-82c1-0ee7a9b74720</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'reddit_video': {'bitrate_kbps': 4800, 'fallb...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>Meme</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'e': 'text', 't': 'fannypackphantom is my re...</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624541e+09</td>\n",
       "      <td>richtext</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>richtext</td>\n",
       "      <td>v.redd.it</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confidence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://v.redd.it/wmjjmyumf5771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0513bea8-4f64-11e9-886d-0e2b4fe7300c</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>fannypackphantom is my real dad</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#014980</td>\n",
       "      <td>o6udmp</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fayde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>some_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>dark</td>\n",
       "      <td>/r/wallstreetbets/comments/o6udmp/retard_gets_...</td>\n",
       "      <td>some_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://v.redd.it/wmjjmyumf5771</td>\n",
       "      <td>10582267</td>\n",
       "      <td>1.624512e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>{'reddit_video': {'bitrate_kbps': 4800, 'fallb...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Hello my follow Apes, $AMC to the moon, but al...</td>\n",
       "      <td>t2_a1okascq</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>$SRNE COVI-STIX EUA approval and DOD CRADA</td>\n",
       "      <td>[{'e': 'text', 't': 'DD'}]</td>\n",
       "      <td>r/wallstreetbets</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>dd</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_o6u5j9</td>\n",
       "      <td>False</td>\n",
       "      <td>light</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>DD</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>richtext</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>False</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confidence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'giver_coin_reward': 0, 'subreddit_id': None...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>5692ce02-b860-11e5-b542-0edc7016bbd3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#365b8c</td>\n",
       "      <td>o6u5j9</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>StocktraderDK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>some_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/wallstreetbets/comments/o6u5j9/srne_covisti...</td>\n",
       "      <td>some_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>10582267</td>\n",
       "      <td>1.624511e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>$WISH - Due Diligence\\n\\nCurrent Price $13.60 ...</td>\n",
       "      <td>t2_16kvla</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>$Wish Due Diligence</td>\n",
       "      <td>[{'e': 'text', 't': 'DD'}]</td>\n",
       "      <td>r/wallstreetbets</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>dd</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_o6u0dt</td>\n",
       "      <td>False</td>\n",
       "      <td>light</td>\n",
       "      <td>0.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>DD</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'gid_1': 1}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>richtext</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>True</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confidence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'giver_coin_reward': None, 'subreddit_id': N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>5692ce02-b860-11e5-b542-0edc7016bbd3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#365b8c</td>\n",
       "      <td>o6u0dt</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>danktim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>some_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/wallstreetbets/comments/o6u0dt/wish_due_dil...</td>\n",
       "      <td>some_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>10582267</td>\n",
       "      <td>1.624511e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_7xgi0cn6</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Quick 30-50 pip overnight for AUD/USD future o...</td>\n",
       "      <td>[{'e': 'text', 't': 'Technical Analysis'}]</td>\n",
       "      <td>r/wallstreetbets</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>chart</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_o6tyxe</td>\n",
       "      <td>False</td>\n",
       "      <td>light</td>\n",
       "      <td>0.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>Technical Analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>richtext</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confidence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://i.redd.it/2pxz8tqua5771.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>e7bce9ea-4b49-11eb-ad96-0e210774c543</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#ff4500</td>\n",
       "      <td>o6tyxe</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bidzero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>some_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/wallstreetbets/comments/o6tyxe/quick_3050_p...</td>\n",
       "      <td>some_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/2pxz8tqua5771.jpg</td>\n",
       "      <td>10582267</td>\n",
       "      <td>1.624511e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  approved_at_utc       subreddit  \\\n",
       "0           0              NaN  wallstreetbets   \n",
       "1           1              NaN  wallstreetbets   \n",
       "2           2              NaN  wallstreetbets   \n",
       "3           3              NaN  wallstreetbets   \n",
       "4           4              NaN  wallstreetbets   \n",
       "\n",
       "                                            selftext author_fullname  saved  \\\n",
       "0                                                NaN     t2_5cnwr7fm  False   \n",
       "1                                                NaN        t2_458fq  False   \n",
       "2  Hello my follow Apes, $AMC to the moon, but al...     t2_a1okascq  False   \n",
       "3  $WISH - Due Diligence\\n\\nCurrent Price $13.60 ...       t2_16kvla  False   \n",
       "4                                                NaN     t2_7xgi0cn6  False   \n",
       "\n",
       "   mod_reason_title  gilded  clicked  \\\n",
       "0               NaN       0    False   \n",
       "1               NaN       0    False   \n",
       "2               NaN       0    False   \n",
       "3               NaN       0    False   \n",
       "4               NaN       0    False   \n",
       "\n",
       "                                               title  \\\n",
       "0  Pentagon UAP report supposed to be released by...   \n",
       "1                          Retard gets a margin call   \n",
       "2         $SRNE COVI-STIX EUA approval and DOD CRADA   \n",
       "3                                $Wish Due Diligence   \n",
       "4  Quick 30-50 pip overnight for AUD/USD future o...   \n",
       "\n",
       "                          link_flair_richtext subreddit_name_prefixed  hidden  \\\n",
       "0                [{'e': 'text', 't': 'News'}]        r/wallstreetbets   False   \n",
       "1                [{'e': 'text', 't': 'Meme'}]        r/wallstreetbets   False   \n",
       "2                  [{'e': 'text', 't': 'DD'}]        r/wallstreetbets   False   \n",
       "3                  [{'e': 'text', 't': 'DD'}]        r/wallstreetbets   False   \n",
       "4  [{'e': 'text', 't': 'Technical Analysis'}]        r/wallstreetbets   False   \n",
       "\n",
       "   pwls link_flair_css_class  downs  top_awarded_type  hide_score       name  \\\n",
       "0     7                 news      0               NaN        True  t3_o6ugzt   \n",
       "1     7                 meme      0               NaN        True  t3_o6udmp   \n",
       "2     7                   dd      0               NaN        True  t3_o6u5j9   \n",
       "3     7                   dd      0               NaN        True  t3_o6u0dt   \n",
       "4     7                chart      0               NaN        True  t3_o6tyxe   \n",
       "\n",
       "   quarantine link_flair_text_color  upvote_ratio  \\\n",
       "0       False                 light          0.75   \n",
       "1       False                 light          0.84   \n",
       "2       False                 light          0.65   \n",
       "3       False                 light          0.74   \n",
       "4       False                 light          0.63   \n",
       "\n",
       "  author_flair_background_color subreddit_type  ups  total_awards_received  \\\n",
       "0                           NaN         public    4                      0   \n",
       "1                       #dadada         public   17                      0   \n",
       "2                           NaN         public    6                      1   \n",
       "3                           NaN         public   29                      1   \n",
       "4                           NaN         public    2                      0   \n",
       "\n",
       "  media_embed              author_flair_template_id  is_original_content  \\\n",
       "0          {}                                   NaN                False   \n",
       "1          {}  78806c26-46a2-11e9-82c1-0ee7a9b74720                False   \n",
       "2          {}                                   NaN                False   \n",
       "3          {}                                   NaN                False   \n",
       "4          {}                                   NaN                False   \n",
       "\n",
       "  user_reports                                       secure_media  \\\n",
       "0           []                                                NaN   \n",
       "1           []  {'reddit_video': {'bitrate_kbps': 4800, 'fallb...   \n",
       "2           []                                                NaN   \n",
       "3           []                                                NaN   \n",
       "4           []                                                NaN   \n",
       "\n",
       "   is_reddit_media_domain  is_meta  category secure_media_embed  \\\n",
       "0                   False    False       NaN                 {}   \n",
       "1                    True    False       NaN                 {}   \n",
       "2                   False    False       NaN                 {}   \n",
       "3                   False    False       NaN                 {}   \n",
       "4                    True    False       NaN                 {}   \n",
       "\n",
       "      link_flair_text  can_mod_post  score  approved_by  \\\n",
       "0                News         False      4          NaN   \n",
       "1                Meme         False     17          NaN   \n",
       "2                  DD         False      6          NaN   \n",
       "3                  DD         False     29          NaN   \n",
       "4  Technical Analysis         False      2          NaN   \n",
       "\n",
       "   is_created_from_ads_ui author_premium  thumbnail edited  \\\n",
       "0                   False          False        NaN  False   \n",
       "1                   False           True        NaN  False   \n",
       "2                   False          False        NaN  False   \n",
       "3                   False           True        NaN  False   \n",
       "4                   False          False        NaN  False   \n",
       "\n",
       "   author_flair_css_class                              author_flair_richtext  \\\n",
       "0                     NaN                                                 []   \n",
       "1                     NaN  [{'e': 'text', 't': 'fannypackphantom is my re...   \n",
       "2                     NaN                                                 []   \n",
       "3                     NaN                                                 []   \n",
       "4                     NaN                                                 []   \n",
       "\n",
       "       gildings  content_categories  is_self  mod_note       created  \\\n",
       "0            {}                 NaN    False       NaN  1.624542e+09   \n",
       "1            {}                 NaN    False       NaN  1.624541e+09   \n",
       "2            {}                 NaN     True       NaN  1.624540e+09   \n",
       "3  {'gid_1': 1}                 NaN     True       NaN  1.624540e+09   \n",
       "4            {}                 NaN    False       NaN  1.624540e+09   \n",
       "\n",
       "  link_flair_type  wls  removed_by_category  banned_by author_flair_type  \\\n",
       "0        richtext    7                  NaN        NaN              text   \n",
       "1        richtext    7                  NaN        NaN          richtext   \n",
       "2        richtext    7                  NaN        NaN              text   \n",
       "3        richtext    7                  NaN        NaN              text   \n",
       "4        richtext    7                  NaN        NaN              text   \n",
       "\n",
       "                domain  allow_live_comments  \\\n",
       "0        dailywire.com                False   \n",
       "1            v.redd.it                False   \n",
       "2  self.wallstreetbets                False   \n",
       "3  self.wallstreetbets                 True   \n",
       "4            i.redd.it                False   \n",
       "\n",
       "                                       selftext_html  likes suggested_sort  \\\n",
       "0                                                NaN    NaN     confidence   \n",
       "1                                                NaN    NaN     confidence   \n",
       "2  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...    NaN     confidence   \n",
       "3  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...    NaN     confidence   \n",
       "4                                                NaN    NaN     confidence   \n",
       "\n",
       "   banned_at_utc                             url_overridden_by_dest  \\\n",
       "0            NaN  https://www.dailywire.com/news/pentagon-ufo-re...   \n",
       "1            NaN                    https://v.redd.it/wmjjmyumf5771   \n",
       "2            NaN                                                NaN   \n",
       "3            NaN                                                NaN   \n",
       "4            NaN                https://i.redd.it/2pxz8tqua5771.jpg   \n",
       "\n",
       "   view_count  archived  no_follow  is_crosspostable  pinned  over_18  \\\n",
       "0         NaN     False      False             False   False    False   \n",
       "1         NaN     False      False             False   False    False   \n",
       "2         NaN     False      False             False   False    False   \n",
       "3         NaN     False      False             False   False    False   \n",
       "4         NaN     False       True             False   False    False   \n",
       "\n",
       "                                       all_awardings awarders  media_only  \\\n",
       "0                                                 []       []       False   \n",
       "1                                                 []       []       False   \n",
       "2  [{'giver_coin_reward': 0, 'subreddit_id': None...       []       False   \n",
       "3  [{'giver_coin_reward': None, 'subreddit_id': N...       []       False   \n",
       "4                                                 []       []       False   \n",
       "\n",
       "                 link_flair_template_id  can_gild  spoiler  locked  \\\n",
       "0  519c3d26-4acc-11eb-8ce2-0ec530aa616d     False    False   False   \n",
       "1  0513bea8-4f64-11e9-886d-0e2b4fe7300c     False    False   False   \n",
       "2  5692ce02-b860-11e5-b542-0edc7016bbd3     False    False   False   \n",
       "3  5692ce02-b860-11e5-b542-0edc7016bbd3     False    False   False   \n",
       "4  e7bce9ea-4b49-11eb-ad96-0e210774c543     False    False   False   \n",
       "\n",
       "                 author_flair_text treatment_tags  visited  removed_by  \\\n",
       "0                              NaN             []    False         NaN   \n",
       "1  fannypackphantom is my real dad             []    False         NaN   \n",
       "2                              NaN             []    False         NaN   \n",
       "3                              NaN             []    False         NaN   \n",
       "4                              NaN             []    False         NaN   \n",
       "\n",
       "   num_reports  distinguished subreddit_id  mod_reason_by  removal_reason  \\\n",
       "0          NaN            NaN     t5_2th52            NaN             NaN   \n",
       "1          NaN            NaN     t5_2th52            NaN             NaN   \n",
       "2          NaN            NaN     t5_2th52            NaN             NaN   \n",
       "3          NaN            NaN     t5_2th52            NaN             NaN   \n",
       "4          NaN            NaN     t5_2th52            NaN             NaN   \n",
       "\n",
       "  link_flair_background_color      id  is_robot_indexable  report_reasons  \\\n",
       "0                     #ffb000  o6ugzt                True             NaN   \n",
       "1                     #014980  o6udmp                True             NaN   \n",
       "2                     #365b8c  o6u5j9                True             NaN   \n",
       "3                     #365b8c  o6u0dt                True             NaN   \n",
       "4                     #ff4500  o6tyxe                True             NaN   \n",
       "\n",
       "             author  discussion_type  num_comments  send_replies  \\\n",
       "0  alexbinfordwalsh              NaN             7          True   \n",
       "1             Fayde              NaN             2          True   \n",
       "2     StocktraderDK              NaN             6          True   \n",
       "3           danktim              NaN            30          True   \n",
       "4           Bidzero              NaN             5          True   \n",
       "\n",
       "  whitelist_status  contest_mode mod_reports author_patreon_flair  \\\n",
       "0         some_ads         False          []                False   \n",
       "1         some_ads         False          []                False   \n",
       "2         some_ads         False          []                False   \n",
       "3         some_ads         False          []                False   \n",
       "4         some_ads         False          []                False   \n",
       "\n",
       "  author_flair_text_color                                          permalink  \\\n",
       "0                     NaN  /r/wallstreetbets/comments/o6ugzt/pentagon_uap...   \n",
       "1                    dark  /r/wallstreetbets/comments/o6udmp/retard_gets_...   \n",
       "2                     NaN  /r/wallstreetbets/comments/o6u5j9/srne_covisti...   \n",
       "3                     NaN  /r/wallstreetbets/comments/o6u0dt/wish_due_dil...   \n",
       "4                     NaN  /r/wallstreetbets/comments/o6tyxe/quick_3050_p...   \n",
       "\n",
       "  parent_whitelist_status  stickied  \\\n",
       "0                some_ads     False   \n",
       "1                some_ads     False   \n",
       "2                some_ads     False   \n",
       "3                some_ads     False   \n",
       "4                some_ads     False   \n",
       "\n",
       "                                                 url  subreddit_subscribers  \\\n",
       "0  https://www.dailywire.com/news/pentagon-ufo-re...               10582267   \n",
       "1                    https://v.redd.it/wmjjmyumf5771               10582267   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...               10582267   \n",
       "3  https://www.reddit.com/r/wallstreetbets/commen...               10582267   \n",
       "4                https://i.redd.it/2pxz8tqua5771.jpg               10582267   \n",
       "\n",
       "    created_utc  num_crossposts  \\\n",
       "0  1.624513e+09               0   \n",
       "1  1.624512e+09               0   \n",
       "2  1.624511e+09               0   \n",
       "3  1.624511e+09               0   \n",
       "4  1.624511e+09               0   \n",
       "\n",
       "                                               media  is_video media_metadata  \\\n",
       "0                                                NaN     False            NaN   \n",
       "1  {'reddit_video': {'bitrate_kbps': 4800, 'fallb...      True            NaN   \n",
       "2                                                NaN     False            NaN   \n",
       "3                                                NaN     False            NaN   \n",
       "4                                                NaN     False            NaN   \n",
       "\n",
       "  is_gallery gallery_data author_cakeday  \n",
       "0        NaN          NaN            NaN  \n",
       "1        NaN          NaN            NaN  \n",
       "2        NaN          NaN            NaN  \n",
       "3        NaN          NaN            NaN  \n",
       "4        NaN          NaN            NaN  "
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 5 rows of the dataset\n",
    "wsb.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>hidden</th>\n",
       "      <th>pwls</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th>downs</th>\n",
       "      <th>thumbnail_height</th>\n",
       "      <th>top_awarded_type</th>\n",
       "      <th>hide_score</th>\n",
       "      <th>name</th>\n",
       "      <th>quarantine</th>\n",
       "      <th>link_flair_text_color</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>subreddit_type</th>\n",
       "      <th>ups</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>media_embed</th>\n",
       "      <th>thumbnail_width</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>secure_media</th>\n",
       "      <th>is_reddit_media_domain</th>\n",
       "      <th>is_meta</th>\n",
       "      <th>category</th>\n",
       "      <th>secure_media_embed</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>can_mod_post</th>\n",
       "      <th>score</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>is_created_from_ads_ui</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>edited</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>gildings</th>\n",
       "      <th>content_categories</th>\n",
       "      <th>is_self</th>\n",
       "      <th>mod_note</th>\n",
       "      <th>created</th>\n",
       "      <th>link_flair_type</th>\n",
       "      <th>wls</th>\n",
       "      <th>removed_by_category</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>domain</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>selftext_html</th>\n",
       "      <th>likes</th>\n",
       "      <th>suggested_sort</th>\n",
       "      <th>banned_at_utc</th>\n",
       "      <th>view_count</th>\n",
       "      <th>archived</th>\n",
       "      <th>no_follow</th>\n",
       "      <th>is_crosspostable</th>\n",
       "      <th>pinned</th>\n",
       "      <th>over_18</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>awarders</th>\n",
       "      <th>media_only</th>\n",
       "      <th>link_flair_template_id</th>\n",
       "      <th>can_gild</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>locked</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>treatment_tags</th>\n",
       "      <th>visited</th>\n",
       "      <th>removed_by</th>\n",
       "      <th>num_reports</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>mod_reason_by</th>\n",
       "      <th>removal_reason</th>\n",
       "      <th>link_flair_background_color</th>\n",
       "      <th>id</th>\n",
       "      <th>is_robot_indexable</th>\n",
       "      <th>report_reasons</th>\n",
       "      <th>author</th>\n",
       "      <th>discussion_type</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>contest_mode</th>\n",
       "      <th>mod_reports</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>permalink</th>\n",
       "      <th>parent_whitelist_status</th>\n",
       "      <th>stickied</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>preview</th>\n",
       "      <th>url_overridden_by_dest</th>\n",
       "      <th>media_metadata</th>\n",
       "      <th>author_cakeday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>What stocks are on your radar this week?\\n\\nWh...</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[Weekly Megathread] Markets and Value Stock Id...</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/ValueInvesting</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_o4nign</td>\n",
       "      <td>False</td>\n",
       "      <td>dark</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>self</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624280e+09</td>\n",
       "      <td>text</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>self.ValueInvesting</td>\n",
       "      <td>True</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>8d92185c-edb3-11e6-8dd4-0e4929a1383e</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t5_2rndg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#d3d6da</td>\n",
       "      <td>o4nign</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/ValueInvesting/comments/o4nign/weekly_megat...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/r/ValueInvesting/commen...</td>\n",
       "      <td>104199</td>\n",
       "      <td>1.624252e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>Hi guys...I have gotten into Value Investing f...</td>\n",
       "      <td>t2_bskz8ifj</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Weekly Learning/Discussion Group on getting be...</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/ValueInvesting</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_o6p2gk</td>\n",
       "      <td>False</td>\n",
       "      <td>dark</td>\n",
       "      <td>0.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>Investing Tools</td>\n",
       "      <td>False</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>self</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624521e+09</td>\n",
       "      <td>text</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>self.ValueInvesting</td>\n",
       "      <td>False</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>2a9f70c8-e6e8-11ea-9b7d-0ecbed16a54b</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t5_2rndg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#d3d6da</td>\n",
       "      <td>o6p2gk</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BhimDigital</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/ValueInvesting/comments/o6p2gk/weekly_learn...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/ValueInvesting/commen...</td>\n",
       "      <td>104199</td>\n",
       "      <td>1.624492e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>I wasn't sure what to expect when I started th...</td>\n",
       "      <td>t2_5406jb4v</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Intrinsic valuation of Verizon ($VZ) - 30% Und...</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/ValueInvesting</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_o6nd1r</td>\n",
       "      <td>False</td>\n",
       "      <td>dark</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>Stock Analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>self</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624515e+09</td>\n",
       "      <td>text</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>self.ValueInvesting</td>\n",
       "      <td>False</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>4ff25162-eaaa-11e6-96fb-0ee5464b8f94</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t5_2rndg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#d3d6da</td>\n",
       "      <td>o6nd1r</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k_ristovski</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/ValueInvesting/comments/o6nd1r/intrinsic_va...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/ValueInvesting/commen...</td>\n",
       "      <td>104199</td>\n",
       "      <td>1.624487e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>self</td>\n",
       "      <td>{'images': [{'source': {'url': 'https://extern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_148imk</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Peter Lynch: 10 Investing Mistakes Everyone Makes</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/ValueInvesting</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_o6b8my</td>\n",
       "      <td>False</td>\n",
       "      <td>dark</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>{'content': '&amp;lt;iframe width=\"356\" height=\"20...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'type': 'youtube.com', 'oembed': {'provider_u...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'content': '&amp;lt;iframe width=\"356\" height=\"20...</td>\n",
       "      <td>Stock Analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://b.thumbs.redditmedia.com/PnrAX-iaGrozw...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624478e+09</td>\n",
       "      <td>text</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>youtu.be</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'giver_coin_reward': None, 'subreddit_id': N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>4ff25162-eaaa-11e6-96fb-0ee5464b8f94</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t5_2rndg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#d3d6da</td>\n",
       "      <td>o6b8my</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELeCtRiCiTy_zAp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/ValueInvesting/comments/o6b8my/peter_lynch_...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://youtu.be/c6dv82lQf9c</td>\n",
       "      <td>104199</td>\n",
       "      <td>1.624449e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>{'type': 'youtube.com', 'oembed': {'provider_u...</td>\n",
       "      <td>False</td>\n",
       "      <td>rich:video</td>\n",
       "      <td>{'images': [{'source': {'url': 'https://extern...</td>\n",
       "      <td>https://youtu.be/c6dv82lQf9c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>Today is PSTH's (Pershing Square Tontine Holdi...</td>\n",
       "      <td>t2_9ak94exb</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>PSTH's Analyst Day about Universal Music Group</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/ValueInvesting</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_o6b89r</td>\n",
       "      <td>False</td>\n",
       "      <td>dark</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>Stock Analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>self</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624478e+09</td>\n",
       "      <td>text</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>self.ValueInvesting</td>\n",
       "      <td>False</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>4ff25162-eaaa-11e6-96fb-0ee5464b8f94</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t5_2rndg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#d3d6da</td>\n",
       "      <td>o6b89r</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EyeOfAgamotto_123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/ValueInvesting/comments/o6b89r/psths_analys...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/ValueInvesting/commen...</td>\n",
       "      <td>104199</td>\n",
       "      <td>1.624449e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>self</td>\n",
       "      <td>{'images': [{'source': {'url': 'https://extern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  approved_at_utc       subreddit  \\\n",
       "0           0              NaN  ValueInvesting   \n",
       "1           1              NaN  ValueInvesting   \n",
       "2           2              NaN  ValueInvesting   \n",
       "3           3              NaN  ValueInvesting   \n",
       "4           4              NaN  ValueInvesting   \n",
       "\n",
       "                                            selftext author_fullname  saved  \\\n",
       "0  What stocks are on your radar this week?\\n\\nWh...        t2_6l4z3  False   \n",
       "1  Hi guys...I have gotten into Value Investing f...     t2_bskz8ifj  False   \n",
       "2  I wasn't sure what to expect when I started th...     t2_5406jb4v  False   \n",
       "3                                                NaN       t2_148imk  False   \n",
       "4  Today is PSTH's (Pershing Square Tontine Holdi...     t2_9ak94exb  False   \n",
       "\n",
       "   mod_reason_title  gilded  clicked  \\\n",
       "0               NaN       0    False   \n",
       "1               NaN       0    False   \n",
       "2               NaN       0    False   \n",
       "3               NaN       0    False   \n",
       "4               NaN       0    False   \n",
       "\n",
       "                                               title link_flair_richtext  \\\n",
       "0  [Weekly Megathread] Markets and Value Stock Id...                  []   \n",
       "1  Weekly Learning/Discussion Group on getting be...                  []   \n",
       "2  Intrinsic valuation of Verizon ($VZ) - 30% Und...                  []   \n",
       "3  Peter Lynch: 10 Investing Mistakes Everyone Makes                  []   \n",
       "4     PSTH's Analyst Day about Universal Music Group                  []   \n",
       "\n",
       "  subreddit_name_prefixed  hidden  pwls  link_flair_css_class  downs  \\\n",
       "0        r/ValueInvesting   False     6                   NaN      0   \n",
       "1        r/ValueInvesting   False     6                   NaN      0   \n",
       "2        r/ValueInvesting   False     6                   NaN      0   \n",
       "3        r/ValueInvesting   False     6                   NaN      0   \n",
       "4        r/ValueInvesting   False     6                   NaN      0   \n",
       "\n",
       "   thumbnail_height top_awarded_type  hide_score       name  quarantine  \\\n",
       "0               NaN              NaN       False  t3_o4nign       False   \n",
       "1               NaN              NaN       False  t3_o6p2gk       False   \n",
       "2               NaN              NaN       False  t3_o6nd1r       False   \n",
       "3             105.0              NaN       False  t3_o6b8my       False   \n",
       "4               NaN              NaN       False  t3_o6b89r       False   \n",
       "\n",
       "  link_flair_text_color  upvote_ratio author_flair_background_color  \\\n",
       "0                  dark          1.00                           NaN   \n",
       "1                  dark          0.94                           NaN   \n",
       "2                  dark          0.72                           NaN   \n",
       "3                  dark          0.90                           NaN   \n",
       "4                  dark          0.90                           NaN   \n",
       "\n",
       "  subreddit_type  ups  total_awards_received  \\\n",
       "0         public    3                      0   \n",
       "1         public   42                      0   \n",
       "2         public   12                      0   \n",
       "3         public   79                      1   \n",
       "4         public   59                      0   \n",
       "\n",
       "                                         media_embed  thumbnail_width  \\\n",
       "0                                                 {}              NaN   \n",
       "1                                                 {}              NaN   \n",
       "2                                                 {}              NaN   \n",
       "3  {'content': '&lt;iframe width=\"356\" height=\"20...            140.0   \n",
       "4                                                 {}              NaN   \n",
       "\n",
       "  author_flair_template_id  is_original_content user_reports  \\\n",
       "0                      NaN                False           []   \n",
       "1                      NaN                False           []   \n",
       "2                      NaN                False           []   \n",
       "3                      NaN                False           []   \n",
       "4                      NaN                False           []   \n",
       "\n",
       "                                        secure_media  is_reddit_media_domain  \\\n",
       "0                                                NaN                   False   \n",
       "1                                                NaN                   False   \n",
       "2                                                NaN                   False   \n",
       "3  {'type': 'youtube.com', 'oembed': {'provider_u...                   False   \n",
       "4                                                NaN                   False   \n",
       "\n",
       "   is_meta  category                                 secure_media_embed  \\\n",
       "0    False       NaN                                                 {}   \n",
       "1    False       NaN                                                 {}   \n",
       "2    False       NaN                                                 {}   \n",
       "3    False       NaN  {'content': '&lt;iframe width=\"356\" height=\"20...   \n",
       "4    False       NaN                                                 {}   \n",
       "\n",
       "   link_flair_text  can_mod_post  score  approved_by  is_created_from_ads_ui  \\\n",
       "0       Discussion         False      3          NaN                   False   \n",
       "1  Investing Tools         False     42          NaN                   False   \n",
       "2   Stock Analysis         False     12          NaN                   False   \n",
       "3   Stock Analysis         False     79          NaN                   False   \n",
       "4   Stock Analysis         False     59          NaN                   False   \n",
       "\n",
       "  author_premium                                          thumbnail edited  \\\n",
       "0           True                                               self  False   \n",
       "1          False                                               self  False   \n",
       "2          False                                               self  False   \n",
       "3          False  https://b.thumbs.redditmedia.com/PnrAX-iaGrozw...  False   \n",
       "4          False                                               self  False   \n",
       "\n",
       "   author_flair_css_class author_flair_richtext gildings  content_categories  \\\n",
       "0                     NaN                    []       {}                 NaN   \n",
       "1                     NaN                    []       {}                 NaN   \n",
       "2                     NaN                    []       {}                 NaN   \n",
       "3                     NaN                    []       {}                 NaN   \n",
       "4                     NaN                    []       {}                 NaN   \n",
       "\n",
       "   is_self  mod_note       created link_flair_type  wls  removed_by_category  \\\n",
       "0     True       NaN  1.624280e+09            text    6                  NaN   \n",
       "1     True       NaN  1.624521e+09            text    6                  NaN   \n",
       "2     True       NaN  1.624515e+09            text    6                  NaN   \n",
       "3    False       NaN  1.624478e+09            text    6                  NaN   \n",
       "4     True       NaN  1.624478e+09            text    6                  NaN   \n",
       "\n",
       "   banned_by author_flair_type               domain  allow_live_comments  \\\n",
       "0        NaN              text  self.ValueInvesting                 True   \n",
       "1        NaN              text  self.ValueInvesting                False   \n",
       "2        NaN              text  self.ValueInvesting                False   \n",
       "3        NaN              text             youtu.be                False   \n",
       "4        NaN              text  self.ValueInvesting                False   \n",
       "\n",
       "                                       selftext_html  likes suggested_sort  \\\n",
       "0  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...    NaN            new   \n",
       "1  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...    NaN            NaN   \n",
       "2  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...    NaN            NaN   \n",
       "3                                                NaN    NaN            NaN   \n",
       "4  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...    NaN            NaN   \n",
       "\n",
       "   banned_at_utc  view_count  archived  no_follow  is_crosspostable  pinned  \\\n",
       "0            NaN         NaN     False      False             False   False   \n",
       "1            NaN         NaN     False      False             False   False   \n",
       "2            NaN         NaN     False      False             False   False   \n",
       "3            NaN         NaN     False      False             False   False   \n",
       "4            NaN         NaN     False      False             False   False   \n",
       "\n",
       "   over_18                                      all_awardings awarders  \\\n",
       "0    False                                                 []       []   \n",
       "1    False                                                 []       []   \n",
       "2    False                                                 []       []   \n",
       "3    False  [{'giver_coin_reward': None, 'subreddit_id': N...       []   \n",
       "4    False                                                 []       []   \n",
       "\n",
       "   media_only                link_flair_template_id  can_gild  spoiler  \\\n",
       "0       False  8d92185c-edb3-11e6-8dd4-0e4929a1383e     False    False   \n",
       "1       False  2a9f70c8-e6e8-11ea-9b7d-0ecbed16a54b     False    False   \n",
       "2       False  4ff25162-eaaa-11e6-96fb-0ee5464b8f94     False    False   \n",
       "3       False  4ff25162-eaaa-11e6-96fb-0ee5464b8f94     False    False   \n",
       "4       False  4ff25162-eaaa-11e6-96fb-0ee5464b8f94     False    False   \n",
       "\n",
       "   locked author_flair_text treatment_tags  visited  removed_by  num_reports  \\\n",
       "0   False               NaN             []    False         NaN          NaN   \n",
       "1   False               NaN             []    False         NaN          NaN   \n",
       "2   False               NaN             []    False         NaN          NaN   \n",
       "3   False               NaN             []    False         NaN          NaN   \n",
       "4   False               NaN             []    False         NaN          NaN   \n",
       "\n",
       "   distinguished subreddit_id  mod_reason_by  removal_reason  \\\n",
       "0            NaN     t5_2rndg            NaN             NaN   \n",
       "1            NaN     t5_2rndg            NaN             NaN   \n",
       "2            NaN     t5_2rndg            NaN             NaN   \n",
       "3            NaN     t5_2rndg            NaN             NaN   \n",
       "4            NaN     t5_2rndg            NaN             NaN   \n",
       "\n",
       "  link_flair_background_color      id  is_robot_indexable  report_reasons  \\\n",
       "0                     #d3d6da  o4nign                True             NaN   \n",
       "1                     #d3d6da  o6p2gk                True             NaN   \n",
       "2                     #d3d6da  o6nd1r                True             NaN   \n",
       "3                     #d3d6da  o6b8my                True             NaN   \n",
       "4                     #d3d6da  o6b89r                True             NaN   \n",
       "\n",
       "              author  discussion_type  num_comments  send_replies  \\\n",
       "0      AutoModerator              NaN            28         False   \n",
       "1        BhimDigital              NaN            64          True   \n",
       "2        k_ristovski              NaN            15          True   \n",
       "3    ELeCtRiCiTy_zAp              NaN             2          True   \n",
       "4  EyeOfAgamotto_123              NaN            18          True   \n",
       "\n",
       "  whitelist_status  contest_mode mod_reports author_patreon_flair  \\\n",
       "0          all_ads         False          []                False   \n",
       "1          all_ads         False          []                False   \n",
       "2          all_ads         False          []                False   \n",
       "3          all_ads         False          []                False   \n",
       "4          all_ads         False          []                False   \n",
       "\n",
       "  author_flair_text_color                                          permalink  \\\n",
       "0                     NaN  /r/ValueInvesting/comments/o4nign/weekly_megat...   \n",
       "1                     NaN  /r/ValueInvesting/comments/o6p2gk/weekly_learn...   \n",
       "2                     NaN  /r/ValueInvesting/comments/o6nd1r/intrinsic_va...   \n",
       "3                     NaN  /r/ValueInvesting/comments/o6b8my/peter_lynch_...   \n",
       "4                     NaN  /r/ValueInvesting/comments/o6b89r/psths_analys...   \n",
       "\n",
       "  parent_whitelist_status  stickied  \\\n",
       "0                 all_ads      True   \n",
       "1                 all_ads     False   \n",
       "2                 all_ads     False   \n",
       "3                 all_ads     False   \n",
       "4                 all_ads     False   \n",
       "\n",
       "                                                 url  subreddit_subscribers  \\\n",
       "0  https://www.reddit.com/r/ValueInvesting/commen...                 104199   \n",
       "1  https://www.reddit.com/r/ValueInvesting/commen...                 104199   \n",
       "2  https://www.reddit.com/r/ValueInvesting/commen...                 104199   \n",
       "3                       https://youtu.be/c6dv82lQf9c                 104199   \n",
       "4  https://www.reddit.com/r/ValueInvesting/commen...                 104199   \n",
       "\n",
       "    created_utc  num_crossposts  \\\n",
       "0  1.624252e+09               0   \n",
       "1  1.624492e+09               0   \n",
       "2  1.624487e+09               0   \n",
       "3  1.624449e+09               0   \n",
       "4  1.624449e+09               0   \n",
       "\n",
       "                                               media  is_video   post_hint  \\\n",
       "0                                                NaN     False         NaN   \n",
       "1                                                NaN     False         NaN   \n",
       "2                                                NaN     False        self   \n",
       "3  {'type': 'youtube.com', 'oembed': {'provider_u...     False  rich:video   \n",
       "4                                                NaN     False        self   \n",
       "\n",
       "                                             preview  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  {'images': [{'source': {'url': 'https://extern...   \n",
       "3  {'images': [{'source': {'url': 'https://extern...   \n",
       "4  {'images': [{'source': {'url': 'https://extern...   \n",
       "\n",
       "         url_overridden_by_dest media_metadata author_cakeday  \n",
       "0                           NaN            NaN            NaN  \n",
       "1                           NaN            NaN            NaN  \n",
       "2                           NaN            NaN            NaN  \n",
       "3  https://youtu.be/c6dv82lQf9c            NaN            NaN  \n",
       "4                           NaN            NaN            NaN  "
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3CAWyIl1cky"
   },
   "source": [
    "<a id='2'></a>\n",
    "# 2. Pre-processing data\n",
    "\n",
    "In this study we will be predicting the subreddit of the post based on the post title and post contents. We will not be using the metadata extracted in the dataset (e.g. upvotes, time posted). With the 'selftext' and 'title', we combine the strings and preprocess it into a bag-of-words text document.\n",
    "\n",
    "In this section we will:\n",
    "\n",
    "- Clean the data\n",
    "- Manipulate the data to 1 clean document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['subreddit', 'selftext', 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb = wsb[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = value[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wallstreetbets data set has alot of posts with videos/picture. These are posts with a short title and a screenshot with no content in the selftext column. We will be dropping these observations, because we have enough data to afford dropping the observations and the short document may add unnecessary variance that can be avoided in the model.\n",
    "\n",
    "We drop observations with NaN in selftext (959 observations from wallstreetbets dataset and 225 observations from valueinvesting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pentagon UAP report supposed to be released by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retard gets a margin call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quick 30-50 pip overnight for AUD/USD future o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$CRSR Good fundamentals are sexy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4MM Yolo $WISH, Caesar is home, where are my a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit selftext                                              title\n",
       "0   wallstreetbets      NaN  Pentagon UAP report supposed to be released by...\n",
       "1   wallstreetbets      NaN                          Retard gets a margin call\n",
       "4   wallstreetbets      NaN  Quick 30-50 pip overnight for AUD/USD future o...\n",
       "5   wallstreetbets      NaN                  $CRSR Good fundamentals are sexy.\n",
       "10  wallstreetbets      NaN  4MM Yolo $WISH, Caesar is home, where are my a..."
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsb[wsb['selftext'].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsb['selftext'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter Lynch: 10 Investing Mistakes Everyone Makes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singapore Exchange - Great Business with a Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Squarespace Inc. $SQSP - A Valuation on 23rd J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How John Maynard Keynes' best years of perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Peter Lynch Playbook - A good summary of P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit selftext                                              title\n",
       "3   ValueInvesting      NaN  Peter Lynch: 10 Investing Mistakes Everyone Makes\n",
       "5   ValueInvesting      NaN  Singapore Exchange - Great Business with a Str...\n",
       "12  ValueInvesting      NaN  Squarespace Inc. $SQSP - A Valuation on 23rd J...\n",
       "17  ValueInvesting      NaN  How John Maynard Keynes' best years of perform...\n",
       "25  ValueInvesting      NaN  The Peter Lynch Playbook - A good summary of P..."
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value[value['selftext'].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value['selftext'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830, 3)"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "value.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(845, 3)"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining observations can be combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine title and selftext\n",
    "wsb['text'] = wsb['title'] + \" \" + wsb['selftext']\n",
    "value['text'] = value['title'] + \" \"  + value['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the datasets\n",
    "df = pd.merge(wsb,value, how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dummy such that class 0 represents posts from r/valueinvesting and class 1 represents posts from r/wallstreetbets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependent Variable - Create dummy where 1 if subreddit = wsb\n",
    "df['subreddit'] = df['subreddit'].map(lambda x: 1 if x == 'wallstreetbets' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample document from wallstreetbet subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$Wish Due Diligence $WISH - Due Diligence\n",
      "\n",
      "Current Price $13.60 \n",
      "Market Cap 8.4\n",
      "Cash 1.77 B\n",
      "Debt 48M\n",
      "52 Week High $32.85 \n",
      "52 Week Low $7.52 \n",
      "Total Cash per share $2.87 \n",
      "\n",
      "\n",
      "Bull Case for Wish\n",
      "1. Growing incredibly fast. \n",
      "2. Impressive revenue numbers. \n",
      "3. Gamify shopping \n",
      "4. Incentive people with daily login discounts. Also to keep buying things by offering games, and gambling spins for a % discount on deals\n",
      "5. Targets a younger audience\n",
      "6. Cost conscience audience\n",
      "7. Impulse purchases\n",
      "8. International platform\n",
      "9. 40% of revenue from USA \n",
      "10. 40% of revenue from Europe \n",
      "11. Merchants from all over the international world \n",
      "12. Advertising program for merchants\n",
      "13. Logistics program for merchants\n",
      "14. Asset light approach\n",
      "15. THE NAME (itâ€™s EASY to remember) \n",
      "16. New partnerships so they donâ€™t have to rely only on their sellers from China. \n",
      "17. 350k+ new sellers from Latin American countries \n",
      "18. Expanding in Africa\n",
      "19. Partnerships in USA will cut down on shipment time, and product quality issues. Already starting to see a shift. \n",
      "20. With the hiring of Jacqueline Reses from Square. Wish might provide financial services to the underbanked and merchants they serve in the future. \n",
      "\n",
      "Price/Sales comparison with other E-commerce Companies \n",
      "\n",
      "Wish 2.9\n",
      "Ebay 4\n",
      "Jmia 17\n",
      "Meli 15.55 \n",
      "Amzn 4.22\n",
      "Pins 23.39 \n",
      "Shop 55.09 \n",
      "Posh 12.11\n",
      "Etsy 12.42 \n",
      "\n",
      "As you can see Wish P/S is significantly lower than its competitors. On 12/31/2020 WISH P/S was 4.37. Wish is trading at only 56% of the    P/S value it was in December. \n",
      "\n",
      "\n",
      "Over the past 12 months Wish has generated almost 3B in revenue. \n",
      "\n",
      "Wish is projected to become profitable in December of 2023 according to analysts projections. \n",
      "\n",
      "Revenue Estimates Year End | YOY Growth | FWD Price/Sales\n",
      "Dec 2021 3.32B | 30.59% 2.13\n",
      "Dec 2022 3.81B | 14.82% 1.85\n",
      "Dec 2023 4.49B | 17.85% 1.57\n",
      "Dec 2024 5.24B | 16.76% 1.35 \n",
      "Dec 2025 5.99B | 14.20% 1.18 \n",
      "Dec 2026 7.40B | 23.62% .95\n",
      "Dec 2027 8.38B | 13.18% .84 \n",
      "Dec 2028 9.43B |12.58% .75 \n",
      "\n",
      "There is no arguing that thing is MUCH MORE ATTRACTIVE than a lot of the other \n",
      "e-commerce stocks out there. \n",
      "\n",
      "I like that there is no debt and almost 2 Billion in the bank. \n",
      "\n",
      "I think that the product quality, and delivery time will become better for the consumer over the next 12 months based on recent hires, and partnerships. \n",
      "\n",
      "Wish local allows the buyer to save money by picking up at one of the wish local locations and allows the small businesses to have an extra revenue stream. \n",
      "Wish boost (sellers can boost their products for a certain amount of time. Similar to tinder or bumble for all you horny fucks out there)\n",
      "\n",
      "Google trends. Wish is trending more THAN DOUBLE what it was in Jan-April. \n",
      "\n",
      "Because of this I expect wish to have strong revenue, and user growth for this upcoming quarter. \n",
      "\n",
      "I like the stock. This is not financial advise. Iâ€™m just an ape ðŸ¦§\n"
     ]
    }
   ],
   "source": [
    "print(df['text'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample document from ValueInvesting subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confused about â€œLittle book that still beats the Marketâ€ by Joel Greenblatt In the value investing world, Joel Greenblatt is one of those value investing gurus. However I found that his â€œmagic formulaâ€ investing strategy was a bit odd especially in relation to the traditional buy below intrinsic value and hold for the long term. In his book he states that buying businesses with a high ROE is the key. This makes sense, however he says that you hold that business for only 1 year and then sell it and then buy new businesses that appear in his magic formula website and then repeat the process. Iâ€™m not sure how this is related to value investing. Maybe Iâ€™m missing something or have misunderstood his strategy. \n",
      "Can anyone fill me in?\n"
     ]
    }
   ],
   "source": [
    "print(df['text'][1202])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text data needs to be preprocessed and cleaned before fitting it into a vectorizer, things we can do to clean the data:\n",
    "\n",
    "1) Remove URLs\n",
    "\n",
    "2) Remove symbols\n",
    "\n",
    "3) Convert to lowercase and split into individual words\n",
    "\n",
    "4) Remove stopwords\n",
    "\n",
    "5) Lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using sklearn's 'english' stop words. Stop words are common words that are uninformative in representing the content of a text. They should be removed to avoid them from being used as a wrong signal for prediction.\n",
    "\n",
    "On top of that we add in additional stop words that can be sensibly removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add words to sklearn stop words\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union([\n",
    "    'wallstreetbets',\n",
    "    'wsb',\n",
    "    'value',\n",
    "    'investing',\n",
    "    'valueinvesting',\n",
    "    'reddit',\n",
    "    'redd',\n",
    "    'june',\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to clean text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML\n",
    "    review_text = BeautifulSoup(text).get_text()\n",
    "\n",
    "    # remove url\n",
    "    no_url = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&\\/;=]*)',' ', review_text)\n",
    "\n",
    "    # Remove non-letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", no_url)\n",
    "\n",
    "    # Convert to lower case and split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    meaningful_words = [w for w in words if w not in stop_words]\n",
    "    \n",
    "    # Lemmatize tokens.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(i) for i in meaningful_words]\n",
    "    return(' '.join(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text in new column\n",
    "\n",
    "df['processed_text'] = df['text'].map(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "# 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For EDA with text data, we can look at 2 aspects, the length of the text and the top 10 frequent words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Length of post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new variable to measure the length of the posts\n",
    "df['text_len'] = df['text'].map(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>845.0</td>\n",
       "      <td>178.454438</td>\n",
       "      <td>280.306420</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>87.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>830.0</td>\n",
       "      <td>441.142169</td>\n",
       "      <td>495.226611</td>\n",
       "      <td>19.0</td>\n",
       "      <td>148.25</td>\n",
       "      <td>269.0</td>\n",
       "      <td>548.5</td>\n",
       "      <td>5445.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count        mean         std   min     25%    50%    75%     max\n",
       "subreddit                                                                   \n",
       "0          845.0  178.454438  280.306420   6.0   50.00   87.0  175.0  2316.0\n",
       "1          830.0  441.142169  495.226611  19.0  148.25  269.0  548.5  5445.0"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary statistics of post length\n",
    "df.groupby('subreddit')['text_len'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above is shows the summary statistics for the reddit post length. From this sample, valueinvesting posts are generally shorter with a mean length of 178 vs 441 for wallstreetbets. This will not be such an issue when classifying the posts. In general, bag of word models do not rely on the length of the document, so the different average length of the post will not be detrimental on our predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the preprocessing steps, we are left with the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new variable to measure the length of the posts\n",
    "df['p_text_len'] = df['processed_text'].map(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>845.0</td>\n",
       "      <td>88.733728</td>\n",
       "      <td>143.273291</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>1166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>830.0</td>\n",
       "      <td>225.086747</td>\n",
       "      <td>257.143935</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>276.75</td>\n",
       "      <td>2935.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count        mean         std   min   25%    50%     75%     max\n",
       "subreddit                                                                  \n",
       "0          845.0   88.733728  143.273291   3.0  24.0   42.0   84.00  1166.0\n",
       "1          830.0  225.086747  257.143935  13.0  74.0  138.0  276.75  2935.0"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary statistics of post length\n",
    "df.groupby('subreddit')['p_text_len'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that there are some observations that have very little words, these observations will not provide predictive power to the model and we will be dropping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['p_text_len'] < 20].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>705.0</td>\n",
       "      <td>103.641135</td>\n",
       "      <td>152.519942</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>825.0</td>\n",
       "      <td>226.360000</td>\n",
       "      <td>257.400033</td>\n",
       "      <td>20.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>2935.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count        mean         std   min   25%    50%    75%     max\n",
       "subreddit                                                                 \n",
       "0          705.0  103.641135  152.519942  20.0  32.0   52.0   95.0  1166.0\n",
       "1          825.0  226.360000  257.400033  20.0  74.0  139.0  278.0  2935.0"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary statistics of post length\n",
    "df.groupby('subreddit')['p_text_len'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average length of valueinvesting posts is now 103 and 226 for wallstreetbets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Histogram of text length')\n",
    "sns.histplot(df['p_text_len'],bins = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get top n words\n",
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r/valueinvesting top 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company 1145\n",
      "stock 913\n",
      "market 648\n",
      "year 632\n",
      "price 543\n",
      "growth 405\n",
      "like 402\n",
      "cash 396\n",
      "business 390\n",
      "share 366\n"
     ]
    }
   ],
   "source": [
    "common_val = get_top_n_words(df[df['subreddit']==0]['processed_text'], 10)\n",
    "for word, freq in common_val:\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r/wallstreetbets top 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company 1666\n",
      "stock 1642\n",
      "share 1373\n",
      "price 1336\n",
      "market 1238\n",
      "year 1144\n",
      "short 889\n",
      "just 818\n",
      "like 807\n",
      "time 735\n"
     ]
    }
   ],
   "source": [
    "common_wsb = get_top_n_words(df[df['subreddit']==1]['processed_text'], 10)\n",
    "for word, freq in common_wsb:\n",
    "    print(word, freq)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the data, the top 10 words seem very similar, this is not surprising as both subreddits are commenting on company stocks and shares in the market. Hopefully there will be other words in the documents that provides predictive power to the model to classify as we are not able to rely on much keywords in the top 10 list.\n",
    "\n",
    "Unique words observed in the top 10 list for value investing are \"cash, business, growth\" which hints to the emphasis on company fundamentals in their investment thesis. \n",
    "\n",
    "A common word used in wallstreetbets is short, presumably from their obsession with ['short-squeezes'](https://www.bloomberg.com/news/articles/2021-01-25/how-wallstreetbets-pushed-gamestop-shares-to-the-moon).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple model (logistic regression)\n",
    "\n",
    "In this part, we start by applying a count vectorizer to the documents and a logistic regression. In the later part of this notebook we will tune the models and optimise for accuracy. We use a simple model as a base model to evaluate the results, this will set the grounds for evaluation for the tuned models as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['processed_text'],\n",
    "    df['subreddit'],\n",
    "    stratify = df['subreddit'],\n",
    "    random_state = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the \"CountVectorizer\"\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             max_features = 500,\n",
    "                             ngram_range = (1,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform train and test data\n",
    "\n",
    "X_train_v = vectorizer.fit_transform(X_train)\n",
    "\n",
    "X_test_v = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999128160418483"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate logistic regression model.\n",
    "lr = LogisticRegression(max_iter=400, random_state = 42)\n",
    "\n",
    "# Fit model to training data.\n",
    "lr.fit(X_train_v, y_train)\n",
    "\n",
    "# Evaluate model on training data.\n",
    "lr.score(X_train_v, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to get 3 evaluation metrics which provides insight to how well the model runs.\n",
    "\n",
    "Accuracy score: How many prediction are correct\n",
    "\n",
    "Specificity: How many negative predictions are correct (r/valueinvesting)\n",
    "\n",
    "Sensitivity: How many positive predictions are correct (r/wallstreetbets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get evaluation metrics\n",
    "def metrics(model,X,y):\n",
    "    pred = model.predict(X)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    print(f'Accuracy Score: {accuracy_score(pred,y)}')\n",
    "    print(f'Specificity: {cm[0,0]/(cm[0,0]+cm[0,1])}')\n",
    "    print(f'Sensitivity: {cm[1,1]/(cm[1,1]+cm[1,0])}')\n",
    "    print('--------------')\n",
    "    print('Confusion Matrix')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5392156862745098"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline score\n",
    "df['subreddit'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have relatively balanced classes with slightly more observations in class 1 (wallstreetbets). The baseline score is 0.539."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8381201044386423\n",
      "Specificity: 0.8522727272727273\n",
      "Sensitivity: 0.8260869565217391\n",
      "--------------\n",
      "Confusion Matrix\n",
      "[[150  26]\n",
      " [ 36 171]]\n"
     ]
    }
   ],
   "source": [
    "metrics(lr,X_test_v,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model when testing on the unseen test data, we have an accuracy score of 0.838. There is evidence of overfitting, where the train data is overfitted so the model has high variance. While the model predicts its own data well ( train accuracy was 0.99) the model drops in performance on unseen data. When tuning the model, we look for parameters that help reduce over fitting and variance (e.g regularisation).\n",
    "\n",
    "Specificity and sensitivity are relatively close, this means the model does not predict 1 class better than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficient analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients of a logistic regression shows the effect of a 1 unit change in the feature. Essentially the higher the coefficient, the more likely the model will predict that the document belongs to the wallstreetbets class. The lower the coefficient, the more likely the model will predict that the document belongs to the valueinvesting class.\n",
    "\n",
    "Unlike the top 10 word count, the coefficients of this model will give a better picture about the unique words that will provide predictive power to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of features and coefficients\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "vocab_coef = pd.DataFrame(lr.coef_.tolist()[0], \n",
    "                         index = vocab,\n",
    "                         columns = ['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratio         -1.188810\n",
       "seen          -1.164740\n",
       "operating     -1.008260\n",
       "cash          -0.958238\n",
       "apple         -0.904401\n",
       "produce       -0.857476\n",
       "say           -0.845572\n",
       "trade         -0.819197\n",
       "far           -0.771648\n",
       "life          -0.715042\n",
       "isn           -0.700808\n",
       "performance   -0.699055\n",
       "compared      -0.693330\n",
       "problem       -0.685506\n",
       "put           -0.664908\n",
       "got           -0.644027\n",
       "market cap    -0.643999\n",
       "yes           -0.639660\n",
       "best weekly   -0.632960\n",
       "benefit       -0.631255\n",
       "Name: coef, dtype: float64"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_coef['coef'].sort_values(ascending = True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clov          1.607069\n",
       "doe           1.566546\n",
       "gold          1.313185\n",
       "increase      1.161219\n",
       "valuation     1.072913\n",
       "went          1.072684\n",
       "negative      1.071360\n",
       "meme          1.007562\n",
       "com           0.974715\n",
       "china         0.946839\n",
       "competitor    0.928868\n",
       "non           0.915904\n",
       "rate          0.911731\n",
       "idea          0.904394\n",
       "street        0.877268\n",
       "record        0.875693\n",
       "come          0.847835\n",
       "tl            0.822519\n",
       "selling       0.815794\n",
       "purchase      0.801179\n",
       "Name: coef, dtype: float64"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_coef['coef'].sort_values(ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick note, many of the features with high coefficients makes sense. For example, we see many keywords associated with fundamental analysis in value investing like ratio, operating, cash (flow). On the other side, for wallstreetbets, we see keywords like meme, CLOV (a memestock), tl(dr). That said, this model has not been tuned and is only providing moderate success in generalising unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "# 5. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last section we fit the model with a count vectorizer and a logistic regression. In this section, we will use gridsearch to determine which is the best model to classify the subreddits.\n",
    "\n",
    "We for vectorizers, we will compare between CountVectorizer and TfidfVectorizer.\n",
    "\n",
    "For classification models, we will compare between Logistic Regression, Support Vector Machines and Naive Bayes classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating pipelines for the models.\n",
    "\n",
    "### Choice of hyper-parameters:\n",
    "\n",
    "##### CountVectorizer & TfidfVectorizer\n",
    "\n",
    "min_df -> ignore terms that have document frequency lower than the threshold. A higher number can help to eliminate noise and prevent overfitting\n",
    "\n",
    "max_df -> ignore terms that have document frequency above the threshold. Similarly, this can eliminate noise and prevent overfitting\n",
    "\n",
    "ngram_range -> n-gram words to be counted in document\n",
    "\n",
    "max_features -> build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "\n",
    "##### Logistic Regression\n",
    "\n",
    "penalty -> to use l1 or l2 penalty term for regularisaion\n",
    "\n",
    "C -> Inverse of regularization strength, smaller values have more regularisation, regularisation will reduce the variance of the model\n",
    "\n",
    "##### SVM\n",
    "\n",
    "C -> Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.\n",
    "\n",
    "kernel -> which kernal trick to apply to features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is setting up the pipeline with the choice of hyperparameters that will be optimised by gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cv_lr = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "p_cv_lr_params = {\n",
    "    'cvec__min_df' : [0,2],\n",
    "    'cvec__max_df' : [0.8,0.9,1],\n",
    "    'cvec__ngram_range' : [(1,1),(1,2) ],\n",
    "    'cvec__max_features' : [1000,2000,None],\n",
    "    'lr__penalty': ['l1','l2'],\n",
    "    'lr__C': (0.01,0.1,1),\n",
    "    'lr__solver' : ['liblinear'],\n",
    "    'lr__random_state' : [42],\n",
    "    'lr__max_iter' : [1000]\n",
    "}\n",
    "\n",
    "gs_cv_lr = GridSearchCV(\n",
    "    p_cv_lr,\n",
    "    p_cv_lr_params,\n",
    "    cv = 3,\n",
    "    verbose = 1,\n",
    "    n_jobs = -1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tv_lr = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "p_tv_lr_params = {\n",
    "    'tvec__min_df' : [0,2],\n",
    "    'tvec__max_df' : [0.8,0.9,1],\n",
    "    'tvec__ngram_range' : [(1,1),(1,2) ],\n",
    "    'tvec__max_features' : [1000,2000,None],\n",
    "    'lr__penalty': ['l1','l2'],\n",
    "    'lr__C': (0.01,0.1,1),\n",
    "    'lr__solver' : ['liblinear'],\n",
    "    'lr__random_state' : [42],\n",
    "    'lr__max_iter' : [1000]\n",
    "}\n",
    "\n",
    "gs_tv_lr = GridSearchCV(\n",
    "    p_tv_lr,\n",
    "    p_tv_lr_params,\n",
    "    cv = 3,\n",
    "    verbose = 1,\n",
    "    n_jobs = -1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cv_svm = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "p_cv_svm_params = {\n",
    "    'cvec__min_df' : [0,2],\n",
    "    'cvec__max_df' : [0.8,0.9,1],\n",
    "    'cvec__ngram_range' : [(1,1),(1,2) ],\n",
    "    'cvec__max_features' : [1000,2000,None],\n",
    "    'svm__kernel': ['linear','poly','rbf'],\n",
    "    'svm__C': [1,10,100],\n",
    "    'svm__random_state' : [42]\n",
    "}\n",
    "\n",
    "gs_cv_svm = GridSearchCV(\n",
    "    p_cv_svm,\n",
    "    p_cv_svm_params,\n",
    "    cv = 3,\n",
    "    verbose = 1,\n",
    "    n_jobs = -1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tv_svm = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "p_tv_svm_params = {\n",
    "    'tvec__min_df' : [0,2],\n",
    "    'tvec__max_df' : [0.8,0.9,1],\n",
    "    'tvec__ngram_range' : [(1,1),(1,2) ],\n",
    "    'tvec__max_features' : [1000,2000,None],\n",
    "    'svm__kernel': ['linear','poly','rbf'],\n",
    "    'svm__C': [1,10,100],\n",
    "    'svm__random_state' : [42]\n",
    "}\n",
    "\n",
    "gs_tv_svm = GridSearchCV(\n",
    "    p_tv_svm,\n",
    "    p_tv_svm_params,\n",
    "    cv = 3,\n",
    "    verbose = 1,\n",
    "    n_jobs = -1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cv_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "p_cv_nb_params = {\n",
    "    'cvec__min_df' : [0,2],\n",
    "    'cvec__max_df' : [0.6,0.8,1],\n",
    "    'cvec__ngram_range' : [(1,1),(1,2)],\n",
    "    'cvec__max_features' : [1000,2000,None],\n",
    "}\n",
    "\n",
    "gs_cv_nb = GridSearchCV(\n",
    "    p_cv_nb,\n",
    "    p_cv_nb_params,\n",
    "    cv = 3,\n",
    "    verbose = 1,\n",
    "    n_jobs = -1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tv_nb = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "p_tv_nb_params = {\n",
    "    'tvec__min_df' : [0,2],\n",
    "    'tvec__max_df' : [0.6,0.8,1],\n",
    "    'tvec__ngram_range' : [(1,1),(1,2)],\n",
    "    'tvec__max_features' : [1000,2000,None],\n",
    "}\n",
    "\n",
    "gs_tv_nb = GridSearchCV(\n",
    "    p_tv_nb,\n",
    "    p_tv_nb_params,\n",
    "    cv = 3,\n",
    "    verbose = 1,\n",
    "    n_jobs = -1, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwtan\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.67566379 0.89623574 0.84304585 0.89710607 0.87182344 0.89448826\n",
      " 0.67566379 0.89361794 0.84304585 0.89623119 0.86921931 0.8927499\n",
      " 0.67566379 0.89449282 0.84304358 0.89361111 0.87443668 0.89361111\n",
      " 0.67566379 0.89274762 0.84217325 0.89797639 0.86921247 0.89362022\n",
      " 0.67566379 0.89972159 0.84304585 0.90146223 0.87705676 0.90495036\n",
      " 0.67566379 0.89797639 0.84304585 0.90495263 0.87443896 0.90059419\n",
      " 0.67566379 0.89885127 0.84391618 0.90320743 0.87269376 0.90233255\n",
      " 0.67566379 0.89623347 0.84304358 0.90233483 0.87008052 0.89885127\n",
      " 0.67566379 0.89884671 0.84304585 0.90669783 0.87705676 0.90495263\n",
      " 0.67566379 0.90408003 0.84304585 0.90408003 0.87531156 0.90495263\n",
      " 0.67566379 0.89710379 0.84304358 0.90146223 0.87443896 0.90495036\n",
      " 0.67566379 0.90233255 0.84304358 0.90582068 0.87095084 0.90058963\n",
      " 0.67566379 0.89623574 0.84304585 0.89710607 0.87182344 0.89448826\n",
      " 0.67566379 0.89361794 0.84304585 0.89623119 0.86921931 0.8927499\n",
      " 0.67566379 0.89449282 0.84304358 0.89361111 0.87443668 0.89361111\n",
      " 0.67566379 0.89274762 0.84217325 0.89797639 0.86921247 0.89362022\n",
      " 0.67566379 0.89972159 0.84304585 0.90146223 0.87705676 0.90495036\n",
      " 0.67566379 0.89797639 0.84304585 0.90495263 0.87443896 0.90059419\n",
      " 0.67566379 0.89885127 0.84391618 0.90320743 0.87269376 0.90233255\n",
      " 0.67566379 0.89623347 0.84304358 0.90233483 0.87008052 0.89885127\n",
      " 0.67566379 0.89884671 0.84304585 0.90669783 0.87705676 0.90495263\n",
      " 0.67566379 0.90408003 0.84304585 0.90408003 0.87531156 0.90495263\n",
      " 0.67566379 0.89710379 0.84304358 0.90146223 0.87443896 0.90495036\n",
      " 0.67566379 0.90233255 0.84304358 0.90582068 0.87095084 0.90058963\n",
      " 0.46120232 0.53792736 0.53879768 0.5475214  0.53791824 0.62076743\n",
      " 0.46120232 0.53879996 0.53879768 0.55449765 0.55537253 0.59373961\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.46120232 0.53792736 0.53879768 0.5562383  0.53704792 0.63209757\n",
      " 0.46120232 0.53879996 0.53879768 0.67133269 0.55799261 0.61814507\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.46120232 0.53792736 0.53879768 0.69746969 0.53704792 0.68528746\n",
      " 0.46120232 0.75937647 0.53879768 0.59198073 0.56147162 0.68792121\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.8, 0.9, 1],\n",
       "                         'cvec__max_features': [1000, 2000, None],\n",
       "                         'cvec__min_df': [0, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'lr__C': (0.01, 0.1, 1), 'lr__max_iter': [1000],\n",
       "                         'lr__penalty': ['l1', 'l2'], 'lr__random_state': [42],\n",
       "                         'lr__solver': ['liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwtan\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.46120232 0.46120232 0.46120232 0.46120232 0.46120232 0.46120232\n",
      " 0.46120232 0.46120232 0.46120232 0.46120232 0.46120232 0.46120232\n",
      " 0.46120232 0.46120232 0.46120232 0.46120232 0.46120232 0.46120232\n",
      " 0.46120232 0.46120232 0.46120232 0.46120232 0.46120232 0.46120232\n",
      " 0.46120232 0.46120232        nan        nan 0.46120232 0.46120232\n",
      "        nan        nan 0.46120232 0.46120232        nan        nan\n",
      " 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768\n",
      " 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768\n",
      " 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768\n",
      " 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768\n",
      " 0.53879768 0.53879768        nan        nan 0.53879768 0.53879768\n",
      "        nan        nan 0.53879768 0.53879768        nan        nan\n",
      " 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768\n",
      " 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768\n",
      " 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768\n",
      " 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768 0.53879768\n",
      " 0.53879768 0.53879768        nan        nan 0.53879768 0.53879768\n",
      "        nan        nan 0.53879768 0.53879768        nan        nan\n",
      " 0.83086362 0.83522207 0.83173395 0.83522207 0.80906912 0.80732848\n",
      " 0.8090714  0.80907368 0.74718285 0.59373505 0.77071799 0.73061255\n",
      " 0.83086362 0.83522207 0.83173395 0.83522207 0.80906912 0.80732848\n",
      " 0.8090714  0.80907368 0.74718285 0.59373505 0.77071799 0.73061255\n",
      " 0.53879768 0.53879768        nan        nan 0.53879768 0.53879768\n",
      "        nan        nan 0.53879768 0.53879768        nan        nan\n",
      " 0.85264674 0.85264446 0.85177414 0.85090154 0.84480928 0.84568644\n",
      " 0.84306864 0.84568644 0.82736183 0.78989697 0.82910475 0.83434036\n",
      " 0.85264674 0.85264446 0.85177414 0.85090154 0.84480928 0.84568644\n",
      " 0.84306864 0.84568644 0.82736183 0.78989697 0.82910475 0.83434036\n",
      " 0.53879768 0.53879768        nan        nan 0.53879768 0.53879768\n",
      "        nan        nan 0.53879768 0.53879768        nan        nan\n",
      " 0.91454212 0.91715993 0.91366952 0.91715765 0.91890968 0.9180348\n",
      " 0.92152293 0.91978    0.92500421 0.89711746 0.92238869 0.9189074\n",
      " 0.91454212 0.91715993 0.91366952 0.91715765 0.91890968 0.9180348\n",
      " 0.92152293 0.91978    0.92500421 0.89711746 0.92238869 0.9189074\n",
      " 0.55101181 0.55711317        nan        nan 0.55363416 0.5745629\n",
      "        nan        nan 0.59372594 0.54838717        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lr__C': (0.01, 0.1, 1), 'lr__max_iter': [1000],\n",
       "                         'lr__penalty': ['l1', 'l2'], 'lr__random_state': [42],\n",
       "                         'lr__solver': ['liblinear'],\n",
       "                         'tvec__max_df': [0.8, 0.9, 1],\n",
       "                         'tvec__max_features': [1000, 2000, None],\n",
       "                         'tvec__min_df': [0, 2],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tv_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwtan\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.87357092 0.56493468 0.83783531 0.87357092 0.60853052 0.8613659\n",
      " 0.87357092 0.67130535 0.86746499 0.88054944 0.55970363 0.83609011\n",
      " 0.88054944 0.60940312 0.86485175 0.88054944 0.66956242 0.86921247\n",
      " 0.87182572 0.56667988 0.84218692 0.87182572 0.61376157 0.8604933\n",
      " 0.87182572 0.67217567 0.86658784 0.88141976 0.56231916 0.83957596\n",
      " 0.88141976 0.61114605 0.86659695 0.88141976 0.67130307 0.87095539\n",
      " 0.89013893 0.55621096 0.83434036 0.89013893 0.5980616  0.87618872\n",
      " 0.89013893 0.66346561 0.8788088  0.8953677  0.55097991 0.82998191\n",
      " 0.8953677  0.59632095 0.87444352 0.8953677  0.66346333 0.88054716\n",
      " 0.89014121 0.55970136 0.83521523 0.89014121 0.5980616  0.87357547\n",
      " 0.89014121 0.66346561 0.87706588 0.89449738 0.55359771 0.83259971\n",
      " 0.89449738 0.59719127 0.87269832 0.89449738 0.66520854 0.87706132\n",
      " 0.88665992 0.54574659 0.82562119 0.88665992 0.58584975 0.87532067\n",
      " 0.88665992 0.65212181 0.87706132 0.87706588 0.52831736 0.79336687\n",
      " 0.87706588 0.55621323 0.86399738 0.87706588 0.59369176 0.86661518\n",
      " 0.89014349 0.55010503 0.83085223 0.89014349 0.58934015 0.88055172\n",
      " 0.89014349 0.65648025 0.88055628 0.88665537 0.54575114 0.82475314\n",
      " 0.88665537 0.59195339 0.87618644 0.88665537 0.64776109 0.8770636\n",
      " 0.87357092 0.56493468 0.83783531 0.87357092 0.60853052 0.8613659\n",
      " 0.87357092 0.67130535 0.86746499 0.88054944 0.55970363 0.83609011\n",
      " 0.88054944 0.60940312 0.86485175 0.88054944 0.66956242 0.86921247\n",
      " 0.87182572 0.56667988 0.84218692 0.87182572 0.61376157 0.8604933\n",
      " 0.87182572 0.67217567 0.86658784 0.88141976 0.56231916 0.83957596\n",
      " 0.88141976 0.61114605 0.86659695 0.88141976 0.67130307 0.87095539\n",
      " 0.89013893 0.55621096 0.83434036 0.89013893 0.5980616  0.87618872\n",
      " 0.89013893 0.66346561 0.8788088  0.8953677  0.55097991 0.82998191\n",
      " 0.8953677  0.59632095 0.87444352 0.8953677  0.66346333 0.88054716\n",
      " 0.89014121 0.55970136 0.83521523 0.89014121 0.5980616  0.87357547\n",
      " 0.89014121 0.66346561 0.87706588 0.89449738 0.55359771 0.83259971\n",
      " 0.89449738 0.59719127 0.87269832 0.89449738 0.66520854 0.87706132\n",
      " 0.88665992 0.54574659 0.82562119 0.88665992 0.58584975 0.87532067\n",
      " 0.88665992 0.65212181 0.87706132 0.87706588 0.52831736 0.79336687\n",
      " 0.87706588 0.55621323 0.86399738 0.87706588 0.59369176 0.86661518\n",
      " 0.89014349 0.55010503 0.83085223 0.89014349 0.58934015 0.88055172\n",
      " 0.89014349 0.65648025 0.88055628 0.88665537 0.54575114 0.82475314\n",
      " 0.88665537 0.59195339 0.87618644 0.88665537 0.64776109 0.8770636\n",
      " 0.54142004 0.53792964 0.51874154 0.53880224 0.50568443 0.539668\n",
      " 0.53880224 0.48997079 0.54054288 0.500442   0.53879996 0.49084111\n",
      " 0.500442   0.48386942 0.50217808 0.500442   0.4829991  0.50217808\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.57715792 0.53792964 0.54139953 0.56408031 0.49346803 0.57977344\n",
      " 0.56408031 0.49171144 0.58848578 0.51263562 0.53879996 0.49694704\n",
      " 0.51263562 0.47689773 0.52048446 0.51263562 0.48212422 0.52222966\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62423961 0.53792964 0.58674058 0.60418119 0.4812539  0.6434277\n",
      " 0.60418119 0.48909363 0.64167794 0.55187074 0.46817401 0.52223422\n",
      " 0.53880451 0.46991693 0.53792736 0.53880451 0.47078953 0.51873699\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('svm', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.8, 0.9, 1],\n",
       "                         'cvec__max_features': [1000, 2000, None],\n",
       "                         'cvec__min_df': [0, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'svm__C': [1, 10, 100],\n",
       "                         'svm__kernel': ['linear', 'poly', 'rbf'],\n",
       "                         'svm__random_state': [42]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwtan\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.90669328 0.90234167 0.90494808 0.90233939 0.90843848 0.90931108\n",
      " 0.90756588 0.90844076 0.92238869 0.92588137 0.92152521 0.91715993\n",
      " 0.90669328 0.90234167 0.90494808 0.90233939 0.90843848 0.90931108\n",
      " 0.90756588 0.90844076 0.92238869 0.92588137 0.92152521 0.91715993\n",
      " 0.55101181 0.55624285        nan        nan 0.55363189 0.57455835\n",
      "        nan        nan 0.60594006 0.6373195         nan        nan\n",
      " 0.8944951  0.89275218 0.8927499  0.8918773  0.87271654 0.86922386\n",
      " 0.87358687 0.87445491 0.71580796 0.55362049 0.78556131 0.6504085\n",
      " 0.8944951  0.89275218 0.8927499  0.8918773  0.87271654 0.86922386\n",
      " 0.87358687 0.87445491 0.71580796 0.55362049 0.78556131 0.6504085\n",
      " 0.51962098 0.52049813        nan        nan 0.53530728 0.51614425\n",
      "        nan        nan 0.58501132 0.544031          nan        nan\n",
      " 0.90930424 0.91105628 0.90930197 0.90756816 0.91889829 0.91803025\n",
      " 0.91715537 0.91802797 0.92326357 0.91018824 0.91802797 0.92675169\n",
      " 0.90930424 0.91105628 0.90930197 0.90756816 0.91889829 0.91803025\n",
      " 0.91715537 0.91802797 0.92326357 0.91018824 0.91802797 0.92675169\n",
      " 0.63906698 0.615525          nan        nan 0.659114   0.65562816\n",
      "        nan        nan 0.6442798  0.54054516        nan        nan\n",
      " 0.88315129 0.87879285 0.88228325 0.87879057 0.90233939 0.90059647\n",
      " 0.89884899 0.90320971 0.91105856 0.92414073 0.91280831 0.91715993\n",
      " 0.88315129 0.87879285 0.88228325 0.87879057 0.90233939 0.90059647\n",
      " 0.89884899 0.90320971 0.91105856 0.92414073 0.91280831 0.91715993\n",
      " 0.59286473 0.57891451        nan        nan 0.59111269 0.59373277\n",
      "        nan        nan 0.66087287 0.63120446        nan        nan\n",
      " 0.89188185 0.89187958 0.89100925 0.89100698 0.87794531 0.87358231\n",
      " 0.87707271 0.87707043 0.74457188 0.56582551 0.79340105 0.6826651\n",
      " 0.89188185 0.89187958 0.89100925 0.89100698 0.87794531 0.87358231\n",
      " 0.87707271 0.87707043 0.74457188 0.56582551 0.79340105 0.6826651\n",
      " 0.51962098 0.52049813        nan        nan 0.50741596 0.50392784\n",
      "        nan        nan 0.48387398 0.53967256        nan        nan\n",
      " 0.90582523 0.90495263 0.90408003 0.90495263 0.92064577 0.9171622\n",
      " 0.9171622  0.91542156 0.92675169 0.91367636 0.92413389 0.92675169\n",
      " 0.90582523 0.90495263 0.90408003 0.90495263 0.92064577 0.9171622\n",
      " 0.9171622  0.91542156 0.92675169 0.91367636 0.92413389 0.92675169\n",
      " 0.6399373  0.615525          nan        nan 0.66085693 0.65825052\n",
      "        nan        nan 0.67829071 0.61117566        nan        nan\n",
      " 0.8848965  0.88141065 0.88402845 0.87966317 0.89884899 0.89972387\n",
      " 0.89884899 0.90233711 0.90844076 0.92152293 0.91106311 0.91803253\n",
      " 0.8848965  0.88141065 0.88402845 0.87966317 0.89884899 0.89972387\n",
      " 0.89884899 0.90233711 0.90844076 0.92152293 0.91106311 0.91803253\n",
      " 0.59373505 0.57891451        nan        nan 0.59111269 0.59111497\n",
      "        nan        nan 0.61901768 0.54403556        nan        nan\n",
      " 0.89188185 0.89187958 0.89188185 0.89013438 0.87881791 0.87445491\n",
      " 0.87707271 0.87707043 0.74806228 0.56582551 0.79689145 0.6835377\n",
      " 0.89188185 0.89187958 0.89188185 0.89013438 0.87881791 0.87445491\n",
      " 0.87707271 0.87707043 0.74806228 0.56582551 0.79689145 0.6835377\n",
      " 0.51962098 0.52049813        nan        nan 0.50741596 0.50392784\n",
      "        nan        nan 0.48212878 0.53792736        nan        nan\n",
      " 0.90582523 0.90582523 0.90582523 0.90495263 0.91977317 0.9171622\n",
      " 0.9171622  0.91542156 0.92675169 0.91280376 0.92413389 0.92762429\n",
      " 0.90582523 0.90582523 0.90582523 0.90495263 0.91977317 0.9171622\n",
      " 0.9171622  0.91542156 0.92675169 0.91280376 0.92413389 0.92762429\n",
      " 0.6399373  0.615525          nan        nan 0.66085693 0.65825052\n",
      "        nan        nan 0.67829071 0.61117566        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('svm', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'svm__C': [1, 10, 100],\n",
       "                         'svm__kernel': ['linear', 'poly', 'rbf'],\n",
       "                         'svm__random_state': [42],\n",
       "                         'tvec__max_df': [0.8, 0.9, 1],\n",
       "                         'tvec__max_features': [1000, 2000, None],\n",
       "                         'tvec__min_df': [0, 2],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tv_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwtan\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.89972842 0.89972842 0.89885582 0.89885582 0.90669783 0.90582751\n",
      " 0.90931108 0.90757043 0.90496175 0.79597328 0.92327041 0.90757043\n",
      " 0.89972842 0.89972842 0.89885582 0.89885582 0.90669783 0.90582751\n",
      " 0.90931108 0.90757043 0.90496175 0.79597328 0.92327041 0.90757043\n",
      " 0.5300694  0.54751913        nan        nan 0.53356663 0.56408942\n",
      "        nan        nan 0.56758666 0.74716462        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.6, 0.8, 1],\n",
       "                         'cvec__max_features': [1000, 2000, None],\n",
       "                         'cvec__min_df': [0, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwtan\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.90930424 0.90493896 0.90929969 0.90494124 0.92325674 0.91628277\n",
      " 0.92064121 0.91803025 0.85962298 0.7663436  0.89624258 0.84654765\n",
      " 0.90930424 0.90493896 0.90929969 0.90494124 0.92325674 0.91628277\n",
      " 0.92064121 0.91803025 0.85962298 0.7663436  0.89624258 0.84654765\n",
      " 0.54140865 0.55275245        nan        nan 0.54402873 0.56845242\n",
      "        nan        nan 0.59809577 0.66697196        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tvec__max_df': [0.6, 0.8, 1],\n",
       "                         'tvec__max_features': [1000, 2000, None],\n",
       "                         'tvec__min_df': [0, 2],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tv_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is noted that there are warning message that some results in the gridsearch are producing NaN. This should not be alarming as it just means that a certain combination of hyperparameters paired with the train data set produced an invalid accuracy score. As the proportion of scores with nan is not high, we will not be evaluating what is causing the error for time sake, but the gridsearch is still optimised for the parameters chosen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "The 6 model combinations have been optimised by gridsearch. We will evaluate the result by creating a function that generates all the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get evaluation metrics\n",
    "def metrics(model,X_test,y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    \n",
    "    print(f'Train Score: {model.score(X_train,y_train)}')\n",
    "    print(f'Best CV Score: {model.best_score_}')\n",
    "    print('--------------')\n",
    "    print('Test data scores')\n",
    "    print(f'Accuracy Score: {accuracy_score(pred,y_test)}')\n",
    "    print(f'Specificity: {cm[0,0]/(cm[0,0]+cm[0,1])}')\n",
    "    print(f'Sensitivity: {cm[1,1]/(cm[1,1]+cm[1,0])}')\n",
    "    print('--------------')\n",
    "    print('Confusion Matrix')\n",
    "    print(cm)\n",
    "    \n",
    "    print('Best Parameters:')\n",
    "    return model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: CountVectorizer & Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1.0\n",
      "Best CV Score: 0.9066978342196036\n",
      "--------------\n",
      "Test data scores\n",
      "Accuracy Score: 0.8798955613577023\n",
      "Specificity: 0.8693181818181818\n",
      "Sensitivity: 0.8888888888888888\n",
      "--------------\n",
      "Confusion Matrix\n",
      "[[153  23]\n",
      " [ 23 184]]\n",
      "Best Parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.8,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 0,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'lr__C': 0.1,\n",
       " 'lr__max_iter': 1000,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__random_state': 42,\n",
       " 'lr__solver': 'liblinear'}"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(gs_cv_lr,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the model prefers a moderately strong penalty term with the l2 regularisation. There is evidence of overfitting as the train data set scored 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: TfidfVectorizer & Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.980819529206626\n",
      "Best CV Score: 0.925004214910302\n",
      "--------------\n",
      "Test data scores\n",
      "Accuracy Score: 0.9033942558746736\n",
      "Specificity: 0.8465909090909091\n",
      "Sensitivity: 0.9516908212560387\n",
      "--------------\n",
      "Confusion Matrix\n",
      "[[149  27]\n",
      " [ 10 197]]\n",
      "Best Parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 1,\n",
       " 'lr__max_iter': 1000,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__random_state': 42,\n",
       " 'lr__solver': 'liblinear',\n",
       " 'tvec__max_df': 0.8,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 0,\n",
       " 'tvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(gs_tv_lr,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2 performs better than model 1 in the cross val score as well as the test scores in terms of accuracy. While it is generally the better model, we notice that the sensitivity is higher than the specificity. This means that the model better predicts for posts in r/wallstreetbets as compared to r/valueinvesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: CountVectorizer & SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1.0\n",
      "Best CV Score: 0.8953676996614401\n",
      "--------------\n",
      "Test data scores\n",
      "Accuracy Score: 0.8746736292428199\n",
      "Specificity: 0.8806818181818182\n",
      "Sensitivity: 0.8695652173913043\n",
      "--------------\n",
      "Confusion Matrix\n",
      "[[155  21]\n",
      " [ 27 180]]\n",
      "Best Parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.8,\n",
       " 'cvec__max_features': 2000,\n",
       " 'cvec__min_df': 0,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'svm__C': 1,\n",
       " 'svm__kernel': 'linear',\n",
       " 'svm__random_state': 42}"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(gs_cv_svm,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs best with high regularisation and a linear kernel trick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4: TfidfVectorizer & SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1.0\n",
      "Best CV Score: 0.9276242942873156\n",
      "--------------\n",
      "Test data scores\n",
      "Accuracy Score: 0.9086161879895561\n",
      "Specificity: 0.8806818181818182\n",
      "Sensitivity: 0.9323671497584541\n",
      "--------------\n",
      "Confusion Matrix\n",
      "[[155  21]\n",
      " [ 14 193]]\n",
      "Best Parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svm__C': 100,\n",
       " 'svm__kernel': 'rbf',\n",
       " 'svm__random_state': 42,\n",
       " 'tvec__max_df': 0.8,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(gs_tv_svm,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4 performs better than model 3, interestingly the model performs better with low regularisation and an rbf kernal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5: CountVectorizer & Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9755884917175239\n",
      "Best CV Score: 0.9232704058616871\n",
      "--------------\n",
      "Test data scores\n",
      "Accuracy Score: 0.9033942558746736\n",
      "Specificity: 0.8693181818181818\n",
      "Sensitivity: 0.9323671497584541\n",
      "--------------\n",
      "Confusion Matrix\n",
      "[[153  23]\n",
      " [ 14 193]]\n",
      "Best Parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.6,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(gs_cv_nb,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes model works best when max_df is 0.6 and min_df is 2. This model performed very well with 0.903 accuracy score on the test set. Naive Bayes with a very lean count vectoriser, where many words are not considered in documents, performed well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 6: TfidfVectorizer & Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.960767218831735\n",
      "Best CV Score: 0.9232567358823287\n",
      "--------------\n",
      "Test data scores\n",
      "Accuracy Score: 0.8955613577023499\n",
      "Specificity: 0.8636363636363636\n",
      "Sensitivity: 0.9227053140096618\n",
      "--------------\n",
      "Confusion Matrix\n",
      "[[152  24]\n",
      " [ 16 191]]\n",
      "Best Parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.6,\n",
       " 'tvec__max_features': 2000,\n",
       " 'tvec__min_df': 0,\n",
       " 'tvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(gs_tv_nb,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5 performed better than model 6. Similarly, the best model in this gridsearch used a restrictive vectoriser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|#|Vectoriser|Model|Accuracy|\n",
    "|---|---|---|---|\n",
    "|1|CountVectorizer|Logistic|0.879895561|\n",
    "|2|TfidfVectorizer|Logistic|0.903394256|\n",
    "|3|CountVectorizer|SVM|0.874673629|\n",
    "|4|TfidfVectorizer|SVM|0.908616188|\n",
    "|5|CountVectorizer|Naive Bayes|0.903394256|\n",
    "|6|TfidfVectorizer|Naive Bayes|0.895561358|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4 performed the best as it has the highest accuracy and balanced specificity and sensitivity. In general, TfidfVectorizer performs slightly better than count vectorizers. This is because it better filters for important words in the document. The 3 types of model performed similarly, although the SVM did slightly better. I will refrain from commenting on why SVM is better than the other models just because it is the chosen model for this project.\n",
    "\n",
    "In all the models, the train dataset accuracy score remains very high, this is a sign of overfitting. It is possible that a better set of hyperparameters could be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(gs_tv_svm,X_test,y_test);\n",
    "plt.title(\"ROC curve for SVM (Model 5)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5 has a good AUC score of 0.96, this means it is effective at predicting positive cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "# 6. Conclusion and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we took subreddit text data from Reddit, transform the data and seek to create a model that is able to classify the subreddit.\n",
    "\n",
    "We found that using a TfidfVectorizer with a Subjective Vector Machine produced the best results. The model achieved a relatively high accuracy score of 90.9%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "##### Model:\n",
    "\n",
    "The downside of this model being an SVM is that it is a blackbox model, input is coverted to output but there is not much to infer from the model.\n",
    "\n",
    "All the models that were evaluated did not fully solve the issue of overfitting. We still observe very high accuracy score for the train dataset compared to the test dataset. This can be resolved with further tuning the model, where we reduce the variance of the model. It could also be reduce if we had a bigger sample of text.\n",
    "\n",
    "##### Data collection:\n",
    "\n",
    "r/wallstreetbets has 10M followers, r/valueinvesting has 100k followers. The difference in the followers may have some impact on the sample data. \n",
    "\n",
    "r/wallstreetbets had a high proportion of media post, these were dropped at the start of the study as they did not contain any text in the body.\n",
    "\n",
    "The posts collected were collected at different timings and not systematically.\n",
    "\n",
    "All in all the data collection process could be improved if a cleaner dataset was extracted from Reddit. A better subreddit that is similar to r/valueinvesting could be chosen."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DataScience_Classification_Project_Template_ML_+-v2.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
